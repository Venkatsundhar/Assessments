# -*- coding: utf-8 -*-
"""LVADSUSR195_Venkatsundhar_LAB1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mOxfMQVBC8iTOlCQC8QZzs62-se6An2V
"""

import numpy as np
import pandas as pd
import re
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
from sklearn.tree import export_graphviz
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, IsolationForest
from sklearn.model_selection import cross_val_score
from xgboost import XGBClassifier
import xgboost
from lightgbm import LGBMClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import confusion_matrix, classification_report, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc, r2_score, mean_squared_error, accuracy_score, recall_score, silhouette_score, silhouette_samples,mean_absolute_error
warnings.filterwarnings('ignore')

"""1) LOAD THE DATASET"""

df = pd.read_csv('/content/sample_data/Fare prediction.csv')
df.head()

df.info()

"""2) PREPROCESSING"""

# To check null values
df.isnull().sum()

# No null values

# To check for duplicates
df.duplicated().sum()

# No duplicates

df['key'][0][0:2]

# splitting time from key and Calculating time
for i in range(0,50000):
  df['key'][i]=df['key'][i][0:2]
df.head()

# Converting key from string to int (Time in minutes)
df['key'] = pd.to_numeric(df['key'])

df.info()

# Finding outliers using boxplot
for c in df.select_dtypes(include=['int64','float64']).columns:
  sns.boxplot(df[[c]])

# There are outliers we have to treat them
for c in df.select_dtypes(include=['int64','float64']).columns:
  q1 = df[c].quantile(0.25)
  q3 = df[c].quantile(0.75)
  iqr = q3-q1
  lwr = q1-1.5*iqr
  upr = q3+1.5*iqr
  df.loc[df[c]>upr,c]=upr
  df.loc[df[c]<lwr,c]=lwr

# AFter treating outliers
for c in df.select_dtypes(include=['int64','float64']).columns:
  sns.boxplot(df[[c]])

"""3) EDA"""

df.head()

df.shape

df.describe()

df.info()

# Correlation to find the strength between variables
sns.heatmap(df.select_dtypes(include=['int64','float64']).corr(),annot=True,fmt='.2f')

df.columns

X = df[['key', 'pickup_latitude','pickup_longitude','dropoff_longitude', 'dropoff_latitude','passenger_count']]
y = df['fare_amount']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)

s = MinMaxScaler()
X_train = s.fit_transform(X_train)
X_test = s.transform(X_test)

LR = LinearRegression()

LR.fit(X_train,y_train)
predicted = LR.predict(X_test)

print('R2_Score:',r2_score(y_test,predicted))
print('Mean Absolute Error:',mean_absolute_error(y_test,predicted))
print('Mean Squared Error',mean_squared_error(y_test,predicted))
print('RMSE:',np.sqrt(mean_squared_error(y_test,predicted)))