# -*- coding: utf-8 -*-
"""LVADSUSR195_Venkatsundhar-SP_LAB-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19y_bTucS2Aqhxph_F3bZ_0OtA1nelpsg
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder,MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score,classification_report,confusion_matrix,accuracy_score,precision_score,recall_score,f1_score

df = pd.read_csv('/content/sample_data/booking.csv')
df.head(5)

df.info()

df.describe()

#1
df.isnull().sum()

64/36285

# The null values count is less than 1% so we can remove it

df.dropna(inplace=True)

df

#1b to find outliers using box plot
df_num = df.select_dtypes(include=['int64','float64'])
cols = df_num.columns
for c in cols:
  plt.figure(figsize=(10,7))
  sns.boxplot(df[c])
  plt.title(f"Box plot showing {c}")

# as we can see no_of weekend nights,lead time and special request has some outliers

df.columns

#2
#2a
df_cat = df[['type of meal','room type','market segment type','booking status']]
col_cat = df_cat.columns
L = LabelEncoder()
for c in col_cat:
  df[c]=L.fit_transform(df[c])
df #After label encoding

#3a
# Relevance can be found out by using scatter plots / correlation matrix / heatmap

# Scatter plots for numerical data (including categorical which is encoded)
# Scatter plot
df_num = df.select_dtypes(include=['int64','float64'])
cols = df_num.columns
for i in range(len(cols)):
  for j in range(i+1,len(cols)):
    plt.figure(figsize=(9,6))
    plt.scatter(data=df_num,x=cols[i],y=cols[j])
    plt.title(f"Scatter plot {cols[i]} vs {cols[j]}")

# There was a significnt relation between weekend nights and number of week nights
#lets analyse more by correlation matrix

corr = df_num.corr()
sns.heatmap(corr,annot=True,fmt='.2f')

# There isnt much significance between variables ie > 70% there fore well consdider all

df.duplicated().sum()

# No duplicate values are there

df.columns

#4
X = df[['number of adults', 'number of children',
       'number of weekend nights', 'number of week nights', 'type of meal',
       'car parking space', 'room type', 'lead time', 'market segment type',
       'repeated', 'P-C', 'P-not-C', 'average price', 'special requests']]
y = df['booking status']
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=101)
# 20% data is used for TESTING

# Scaling the variables
Scaler = MinMaxScaler()
X_train = Scaler.fit_transform(X_train)
X_test = Scaler.transform(X_test)

#5
LG = LogisticRegression()
LG.fit(X_train,y_train)

# Model evaluation
predicted = LG.predict(X_test)

#6
print("Accuracy score",accuracy_score(y_test,predicted))
print("Recall score",recall_score(y_test,predicted))
print("Precisions score",precision_score(y_test,predicted))
print("F1 score",f1_score(y_test,predicted))
print(classification_report(y_test,predicted))
print(confusion_matrix(y_test,predicted))

