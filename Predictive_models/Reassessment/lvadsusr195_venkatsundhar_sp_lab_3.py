# -*- coding: utf-8 -*-
"""LVADSUSR195_Venkatsundhar-SP_Lab-3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FXF8b5NcWqf7abZUoeHjin5sGKjocg95
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder,MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from matplotlib.ticker import MultipleLocator
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error
import warnings
warnings.filterwarnings("ignore")
from matplotlib.ticker import MultipleLocator

"""1) DATA LOADING: Dataset is in a csv format and has been loaded using pandas"""

df = pd.read_csv('/content/sample_data/Credit Card Customer Data.csv')
df.head()

"""2) EDA: Explore the Data and dimensions and to check if all the categories are mapped to the correct datatype"""

df.info()
# Gives a generic information about the columns and its datatypes

df.shape
# Gives the dimension of the data ie no of rows and cols

df.describe()
# Describes the basic statistical measures like count mean,median etc related to each numerical columns

"""3) Data Preprocessing: To ensure we have a clean dataset by doing analysis that checks for duplicates,null & outliers and treat them accordingly"""

df.isnull().sum()

13/660

df.dropna(inplace=True)
# Dropping null since the null values is less than 1%

df.duplicated().sum()
# We dont have duplicates

for c in df.select_dtypes(include=['int64','float64']):
  plt.figure(figsize=(9,5))
  sns.boxplot(df[c])
  # Identifying outliers using boxplots

# Avg credit card limit and total visits online
for c in df[['Avg_Credit_Limit','Total_visits_online']]:
  q1 = df[c].quantile(0.25)
  q3 = df[c].quantile(0.75)
  iqr = q3-q1
  upr = q3+1.5*iqr
  lwr = q1-1.5*iqr
  df.loc[df[c]>upr,c] = upr
  df.loc[df[c]<lwr,c] = lwr
  # Treating outliers using iqr methods by clipping to upper and lower bound

for c in df[['Avg_Credit_Limit','Total_visits_online']]:
  plt.figure(figsize=(9,5))
  sns.boxplot(df[c])
  # Outlier recheck all outliers have been treated

# Correlation
corr = df[['Avg_Credit_Limit', 'Total_Credit_Cards',
       'Total_visits_bank', 'Total_visits_online', 'Total_calls_made']].corr()
plt.figure(figsize=(12,7))
sns.heatmap(corr,annot=True,fmt='.2f',linewidths=0.5)
# Correlation to check the strength of the variables

"""No need of label encoding as there is no categorical variable"""

# Elbow to determine optimal clusters
sse = []
for c in range(1,11):
  Km = KMeans(n_clusters=c)
  Km.fit(df[['Avg_Credit_Limit', 'Total_Credit_Cards']])
  sse.append(Km.inertia_)
plt.plot(range(1,11),sse)
plt.xlabel('Optimal K value')
plt.ylabel('SSE')
plt.grid()
# By elbow method found that K = 3

# Scaling
S = MinMaxScaler()
for c in df[['Avg_Credit_Limit','Total_visits_online']]:
  df[c] = S.fit_transform(df[[c]])
  # To normalise the data

"""Took two features 'Avg_Credit_Limit', 'Total_Credit_Cards' as using domain knowledge these two are the most suitable features and doesnt change over time to segment the customers."""

# K=3
# KMeans model fit
Km = KMeans(n_clusters=3)
pred = Km.fit_predict(df[['Avg_Credit_Limit', 'Total_Credit_Cards']])
df['cluster'] = pred
Km.cluster_centers_
# To find cluster centers

# KMeans scatter
df1 = df[df['cluster']==0]
df2 = df[df['cluster']==1]
df3 = df[df['cluster']==2]
#df4 = df[df['cluster']==3]
plt.figure(figsize=(15,9))
plt.scatter(df1['Avg_Credit_Limit'],df1['Total_Credit_Cards'],color='red')
plt.scatter(df2['Avg_Credit_Limit'],df2['Total_Credit_Cards'],color='green')
plt.scatter(df3['Avg_Credit_Limit'],df3['Total_Credit_Cards'],color='blue')
#plt.scatter(df4['Avg_Credit_Limit'],df4['Total_Credit_Cards'],color='gray')
plt.scatter(Km.cluster_centers_[:,0],Km.cluster_centers_[:,1],color='black',marker='*',label='centroid')
plt.grid()
#plt.gca().xaxis.set_major_locator(MultipleLocator(8000))  # Set x-axis tick locator to increase by 1
plt.show()

"""As we see the credit card users have been clustered into 3 segements based on credit card limit from 0 to 20000 as category 1. 35000 - 80000 as category-2 and the rest as category-3."""

silhouette_score(df[['Avg_Credit_Limit', 'Total_Credit_Cards']],pred)

'''
To increase the users from 1 segment to another we can do campaigning like free credit cards for these credit stores of particular range
Only way to increase is by making users to improve their avg credit score
A good way is to show them that you know what they need (be empathetic) and personalise the offer. For example,
If you know that the prospect loves to travel, tell them how much they can save when they pay using your credit card.
those people who have visited your credit card pages on your website can be automatically re-targeted through social media with follow- up
 adverts or messaging.

 One of the most tried-and-true methods to encourage credit card usage is by offering incentives. These can take various forms, such as cashback rewards, loyalty points, or discounts.
  Customers are more likely to reach for their credit cards when they know they can earn something in return.
'''

